// LLM Workspace Sandbox
//
// Treats all LLM-suggested paths as untrusted. Validates suggestions into
// `VirtualPath` values and performs I/O only through type-safe functions.

use anyhow::Result;
use jailed_path::{VirtualPath, VirtualRoot};
use std::fs;

#[derive(Clone)]
struct AiWorkspace;

fn main() -> Result<()> {
    // Prepare workspace
    fs::create_dir_all("llm_ws")?;
    let vroot: VirtualRoot<AiWorkspace> = VirtualRoot::try_new_create("llm_ws")?;

    // Simulated LLM suggestions (could be malicious)
    let suggestions = vec![
        "notes/today.txt",
        "../secrets/steal.txt", // traversal attempt
        "/absolute/path/hack.txt", // absolute attempt
        "results/run1/output.log",
    ];

    for s in suggestions {
        match vroot.virtual_join(s) {
            Ok(vp) => {
                let display = vp.virtualpath_display();
                println!("Suggestion '{s}' -> {display}"); // virtual root path
                apply_suggestion(&vp)?;
            }
            Err(e) => println!("Rejected '{s}': {e}"),
        }
    }

    fs::remove_dir_all("llm_ws").ok();
    Ok(())
}

fn apply_suggestion(p: &VirtualPath<AiWorkspace>) -> Result<()> {
    // Create parent dir if needed (virtual semantics)
    p.create_parent_dir_all()?;
    // Log, then write
    let sys = p.as_unvirtual().jailedpath_display();
    println!("Writing to system path: {sys}");
    p.write_string("Generated by LLM tool\n")?;
    Ok(())
}



